{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install groq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcsL4ieHTDHE",
        "outputId": "afeb474f-598d-42f6-838f-e9fd1613b200"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.34.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Downloading groq-0.34.0-py3-none-any.whl (135 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/136.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m133.1/136.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.0/136.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"Sua_Key\"\n"
      ],
      "metadata": {
        "id": "ALmr8HYJT-aW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BNnXMkQ7S1_X"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "from groq import Groq\n",
        "import os\n",
        "load_dotenv()\n",
        "\n",
        "client = Groq(\n",
        "    api_key=os.environ.get(\"GROQ_API\"),  # This is the default and can be omitted\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **temperature**: controla a aleatoriedade das respostas. Valores entre 0.0 e 1.0 são aceitos.\n",
        "- **max_completion_tokens**: define o número máximo de tokens que podem ser gerados pelo modelo. Esse parâmetro substitui o max_tokens em desuso.\n",
        "- **top_p**: controla a diversidade via \"nucleus sampling\" — em torno de 0.5 significa considerar apenas os tokens que somam 50% da probabilidade."
      ],
      "metadata": {
        "id": "z9PBTPgJUiKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Temperature**"
      ],
      "metadata": {
        "id": "ed4tllj4Wi2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Escreva uma frase poética sobre o anoitcer\"\n",
        "\n",
        "# Temperature baixa (0.0) - Mais determinística\n",
        "print(\"Temperature 0.0 (Determinística):\")\n",
        "response_low = client.chat.completions.create(\n",
        "    model=\"openai/gpt-oss-120b\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Você é um poeta minimalista que descreve a natureza de forma simples e direta.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature=0.0\n",
        ")\n",
        "print(f\"Resposta: {response_low.choices[0].message.content}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RthYTW5MWdIj",
        "outputId": "ee601724-304b-4279-96e6-6b81c4176292"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temperature 0.0 (Determinística):\n",
            "Resposta: O céu se veste de sombra, e o silêncio nasce com o anoitecer.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Top_p**"
      ],
      "metadata": {
        "id": "n1Pq1MXJWkzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Complete a frase: 'A inteligência artificial no futuro será...'\"\n",
        "print(\"=== Comparação Top_p ===\\n\")\n",
        "\n",
        "# Top_p baixo (0.1) - Mais focado\n",
        "print(\"Top_p 0.1 (Focado):\")\n",
        "response_focused = client.chat.completions.create(\n",
        "    model=\"openai/gpt-oss-120b\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Você é um futurista que faz previsões sérias e objetivas sobre tecnologia.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature=1.0,  # fixo para comparar só o efeito do top_p\n",
        "    top_p=0.1\n",
        ")\n",
        "print(f\"Resposta: {response_focused.choices[0].message.content}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CzUQ5L3URmU",
        "outputId": "a8d0d289-a1eb-402f-ffdd-19c9d0393fef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Comparação Top_p ===\n",
            "\n",
            "Top_p 0.1 (Focado):\n",
            "Resposta: A inteligência artificial no futuro será **onipresente, altamente especializada e intrinsecamente colaborativa**, desempenhando papéis críticos em praticamente todos os setores da sociedade. Ela evoluirá em três direções principais:\n",
            "\n",
            "1. **Especialização de domínio** – Em vez de um único modelo “generalista” que tenta fazer tudo, veremos redes de IA hiper‑especializadas, treinadas em conjuntos de dados específicos de indústrias (saúde, energia, finanças, manufatura, educação etc.). Cada uma dessas “IA de nicho” será otimizada para maximizar precisão, segurança e conformidade regulatória no seu campo de atuação.\n",
            "\n",
            "2. **Integração transparente** – A IA deixará de ser um “acessório” para se tornar parte integrante da infraestrutura digital. Sistemas de controle de tráfego, redes elétricas, plataformas de aprendizado e até mesmo dispositivos domésticos conversarão entre si por meio de protocolos padronizados, permitindo decisões em tempo real sem intervenção humana direta.\n",
            "\n",
            "3. **Colaboração humano‑IA** – O modelo dominante será o de parceria, onde a IA fornece recomendações, simulações e análises de risco, enquanto os humanos mantêm a supervisão estratégica e ética. Ferramentas de “explainable AI” (XAI) avançarão a ponto de tornar as decisões da IA tão compreensíveis quanto um relatório técnico escrito por um especialista.\n",
            "\n",
            "Além disso, a IA do futuro será **responsável e regulada**: frameworks globais de governança, auditorias automatizadas e mecanismos de “reset” garantirão que os sistemas permaneçam alinhados aos valores sociais e ambientais. Em resumo, a inteligência artificial será onipresente, especializada e colaborativa, atuando como um amplificador de capacidades humanas e como guardiã de padrões de segurança e ética.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}